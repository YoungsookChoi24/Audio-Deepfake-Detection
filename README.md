# Audio Deepfake Detection Literature

### Conference Papers

|Publication Date|Title|Paper|Code|
|:---|:---|---|---|
|2025/9|EMOANTI: AUDIO ANTI-DEEPFAKE WITH REFINED EMOTION-GUIDED REPRESENTATIONS|[link](https://arxiv.org/abs/2509.10781)|[code](https://anonymous.4open.science/r/EmoAnti/README.md)|
|2025/5|Can Emotion Fool Anti-spoofing?|[link](https://arxiv.org/html/2505.23962v1?utm_source=chatgpt.com)||
|2022/5|Deepfake Speech Detection Through Emotion Recognition: A Semantic Approach|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/abstract/document/9747186?casa_token=6jdcDa-j_KQAAAAA:6Lhya10tuMsKoVGTORnGU973aiLoXpJWKNnofnvy3BUaw7BdLHmOFxyAoleYom2DdrN-bQ)||
|2023/8|REAL-TIME DETECTION OF AI-GENERATED SPEECH FOR DEEPFAKE VOICE CONVERSION|[link](https://arxiv.org/abs/2308.12734)||
|2024/4|Towards the Development of a Real-Time Deepfake Audio Detection System in Communication Platforms|[link](https://arxiv.org/abs/2403.11778)||
|2025/5|ALLM4ADD: Unlocking the Capabilities of Audio Large Language Models for Audio Deepfake Detection|[link](https://arxiv.org/abs/2505.11079)|[code](https://github.com/ucas-hao/qwen_audio_for_add)|
|2024/12|The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio|[link](https://arxiv.org/abs/2405.04880)||
|2025/8|Evaluation framework for deepfake speech detection: a comparative study of state-of-the-art deepfake speech detectors|[link](https://www.researchgate.net/publication/394211445_Evaluation_framework_for_deepfake_speech_detection_a_comparative_study_of_state-of-the-art_deepfake_speech_detectors)||
|2025/4|Strong Alone, Stronger Together: Synergizing Modality-Binding Foundation Models with Optimal Transport for Non-Verbal Emotion Recognition|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889257)||
|2025/8|Perturbed Public Voices (P2V): A Dataset for Robust Audio Deepfake Detection|[link](https://arxiv.org/abs/2508.10949)||
|2024/12|Coarse-to-Fine Proposal Refinement Framework for Audio Temporal Forgery Detection and Localization|[link](https://arxiv.org/abs/2407.16554)||
|2023/1|The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance|[link](https://arxiv.org/abs/2204.05177)||
|2025/4|DiffAttack: Imperceptible and Transferable Audio Adversarial Attack via Diffusion Model|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889191)||
|2025/4|Enhancing Expressive Voice Conversion with Discrete Pitch-Conditioned Flow Matching Model|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889108)||
|2025/4|Recursive Feature Learning from Pre-Trained Models for Spoofing Speech Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888985)||
|2025/4|Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890553)||
|2025/4|Explaining Speaker and Spoof Embeddings via Probing|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10887897)||
|2025/4|Low-Resource Text-to-Speech Synthesis Using Noise-Augmented Training of ForwardTacotron|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890686)||
|2025/4|FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888053)||
|2025/4|ZSVC: Zero-shot Style Voice Conversion with Disentangled Latent Diffusion Models and Adversarial Training|[link](https://ieeexplore.ieee.org/document/10888535)||
|2025/4|From Voices to Beats: Enhancing Music Deepfake Detection by Identifying Forgeries in Background|[link](https://ieeexplore.ieee.org/document/10890293)||
|2024|NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models|[link](https://arxiv.org/abs/2403.03100)||
|2022|Automatic speaker verification spoofing and deepfake detection using wav2vec 2.0 and data augmentation|[link](https://arxiv.org/abs/2202.12233)|[code](https://github.com/TakHemlata/SSL_Anti-spoofing)|
|2025|Audio Features Investigation for Singing Voice Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888452)||
|2023|AudioLM: a Language Modeling Approach to Audio Generation|[link](https://arxiv.org/abs/2209.03143)||
|2026/2|Simultaneous speech and background sound recognition in diverse acoustic environments with branched neural networks|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0885230825000932)||
|2025/4|SpecViT: A Custom Vision-Transformer based Approach for Audio Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889022)||
|2025/4|Freeze and Learn: Continual Learning with Selective Freezing for Speech Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889357)||
|2025/4|PET: High-Frequency Temporal Self-Consistency Learning for Partially Deepfake Audio Localization|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889913)||
|2025/4|Leveraging Mixture of Experts for Improved Speech Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890398)|[code](https://github.com/polimi-ispl/moe_speech_deepfake/)|
|2024/6|Listenable Maps for Audio Classifiers|[link](https://arxiv.org/abs/2403.13086)|[Experimental Setup](https://github.com/speechbrain/speechbrain/tree/develop/recipes/ESC50/interpret)|
|2024/9|Fast and Lightweight Voice Replay Attack Detection via Time-Frequency Spectrum Difference|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/abstract/document/10540568)||
|2025/4|Integrating Spectro-Temporal Cross Aggregation and Multi-Scale Dynamic Learning for Audio Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889337)||
|2025/4|Generalize Audio Deepfake Algorithm Recognition via Attribution Enhancement|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10889399)||
|2025/4|Continual Unsupervised Domain Adaptation for Audio Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890538)||
|2025/4|GNCL: A Graph Neural Network with Consistency Loss for Segment-Level Spoofed Speech Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888281)||
|2025/4|Investigating voiced and unvoiced regions of speech for audio deepfake detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890861)||
|2025/4|What Does an Audio Deepfake Detector Focus on? A Study in the Time Domain|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10887568)||
|2025/4|What Affects the Performance of Fake Audio Detection? Analyzing Factors in a Continual Learning Setting|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888114)||
|2025/4|Mixture of Experts Fusion for Fake Audio Detection Using Frozen wav2vec 2.0|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888990)||
|2025|ADVWAVE: STEALTHY ADVERSARIAL JAILBREAK ATTACK AGAINST LARGE AUDIO-LANGUAGE MODELS|[link](https://openreview.net/forum?id=0BujOfTqab)||
|2025/4|Adversarial Training and Gradient Optimization for Partially Deepfake Audio Localization|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890470)|[code](https://github.com/Little-dingding/ATGO)|
|2025|Easy, Interpretable, Effective: openSMILE for voice deepfake detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10890543)||
|2015|Librispeech: An ASR corpus based on public domain audio books|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/7178964)|[datasets](http://www.openslr.org/11)|
|2023|Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale|[link](https://arxiv.org/abs/2306.15687)||
|2025|Modifying Flow Matching for Generative Speech Enhancement|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10888705)||
|2024|GENERATIVE PRE-TRAINING FOR SPEECH WITH FLOW MATCHING|[link](https://arxiv.org/abs/2310.16338)||
|2025|Leveraging distance information for generalized spoofing speech detection|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0885230825000294)||
|2025|Spoofing countermeasure for fake speech detection using brute force features|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0885230824001153)||
|2026|Towards explainable spoofed speech attribution and detection: A probabilistic approach for characterizing speech synthesizer component|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0885230825000658)||
|2026/1|ASVspoof 5: Design, collection and validation of resources for spoofing, deepfake, and adversarial attack detection using crowdsourced speech|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0885230825000506)||
|2025/7|Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation|[link](https://arxiv.org/abs/2507.03468)||
|2025|BFC-Net: Boundary-Frame cross graph attention network for partially spoofed audio localization|[link](https://www-sciencedirect-com.unr.idm.oclc.org/science/article/pii/S0925231225015395)||
|2023|Timbre-Reserved Adversarial Attack in Speaker Identification|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10224300)||
|2023|ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10155166)||
|2024|FTDKD: Frequency-Time Domain Knowledge Distillation for Low-Quality Compressed Audio Deepfake Detection|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10747292)||
|2024|Generalizable Speech Spoofing Detection Against Silence Trimming With Data Augmentation and Multi-Task Meta-Learning|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10557138)||
|2025|ASSD: An AI-Synthesized Speech Detection Scheme Using Whisper Feature and Types Classification|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10842678/)||
|2025|Multi-Task Partially Spoofed Speech Detection Using a Dual-View Graph Neural Network Assisted Segment-Level Module|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/11062085)||
|2025/1|The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio, published in IEEE transactions on Audio, Speech and Language Processing|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10830534?denied=)|[code](https://github.com/xieyuankun/Codecfake)|
|2025/2|Where are We in Audio Deepfake Detection? A Systematic Analysis over Generative and Detection Models, accepted in ACM Transactions on Internet Technology|[link](https://dl.acm.org/doi/abs/10.1145/3736765)|[code](https://github.com/Jessegator/SONAR)|
|2024/10|Audio Deepfake Detection with XLS-R and SLS classfier|[link](https://openreview.net/pdf?id=acJMIXJg2u)|[code](https://github.com/QiShanZhang/SLSforASVspoof-2021-DF/tree/main?tab=readme-ov-file)|
|2024|SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection|[link](https://proceedings.neurips.cc/paper_files/paper/2024/hash/9c7900fac04a701cbed83256b76dbaa3-Abstract-Conference.html)|[code](https://github.com/Eleven4AI/SpeechForensics)|
|2025/5|Supervised Contrastive Learning from Weakly-Labeled Audio Segments for Musical Version Matching|[link](https://arxiv.org/abs/2502.16936)|[code](https://github.com/sony/clews?tab=readme-ov-file)|
|2024/8|Learning Disentangled Audio Representations through Controlled Synthesis|[link](https://openreview.net/forum?id=Fn9ORH8PLl)||
|2024|AND: Audio Network Dissection for Interpreting Deep Acoustic Models|[link](https://proceedings.mlr.press/v235/wu24q.html)|[code](https://github.com/Trustworthy-ML-Lab/Audio_Network_Dissection)|
|2024/4|A Robust Audio Deepfake Detection System via Multi-View Feature|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10446560)||
|2024/4|Does Audio Deepfake Detection Rely on Artifacts?, published in ICASSP2024|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10446558)||
|2024/4|Audio Deepfake Detection With Self-Supervised Wavlm And Multi-Fusion Attentive Classifier, published in ICASSP2024|[link](https://arxiv.org/abs/2312.08089)||
|2024/4|An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection, published in ICASSP2024|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10448196)||
|2024|CHARACTERIZING THE TEMPORAL DYNAMICS OF UNIVERSAL SPEECH REPRESENTATIONS FOR GENERALIZABLE DEEPFAKE DETECTION, published in ICASSPW2024|[link](https://ieeexplore-ieee-org.unr.idm.oclc.org/document/10627750)||
|2025|ADIFF: Explaining Audio Difference using Natural Lanuage, published at ICLR 2025|[link](https://openreview.net/pdf?id=l4fMj4Vnly)|[code](https://github.com/soham97/ADIFF)|
|2024/12|SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection, published in NeurIPS2024|[link](https://nips.cc/virtual/2024/poster/94173)|[code](https://github.com/FireFistisDead/Deepfake-Detection)|
|2025/1|I Can Hear You: Selective Robust Training for Deepfake Audio Detection|[link](https://iclr.cc/virtual/2025/poster/32111)||
|2024/4|Integrating frame-level boundary detection and deepfake detection for locating manipulated regions in partially spoofed audio forgery attacks|[link](https://www.sciencedirect.com/science/article/pii/S088523082300116X)||
|2023/8|UMMAFormer: A Universal Multimodal-adaptive Transformer Framework for Temporal Forgery Localization|[link](https://arxiv.org/pdf/2308.14395)|[code](https://github.com/ymhzyj/UMMAFormer)|
|2023|The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance, published in TASLPRO2023|[link](https://arxiv.org/pdf/2204.05177)||
|2023/5/4|Do You Really Mean That? Content Driven Audio-Visual Deepfake Dataset and Multimodal Method for Temporal Forgery Localization|[link](https://arxiv.org/pdf/2204.06228)|[github](https://github.com/ControlNet/LAV-DF) [kaggle](https://www.kaggle.com/datasets/elin75/localized-audio-visual-deepfake-dataset-lav-df)|
|2024/7|AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset|[link](https://arxiv.org/pdf/2311.15308)|[Dataset](https://github.com/ControlNet/AV-Deepfake1M)||
|2021|A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection|[link](https://www.isca-archive.org/interspeech_2021/wang21fa_interspeech.pdf)|[code](https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts)|
|2024/7/3|Audiotime: A Temporally-aligned Audio-text Benchmark Dataset|[link](https://arxiv.org/pdf/2407.02857)||
|2024/7/23|Coarse-to-Fine Proposal Refinement Framework for Audio Temporal Forgery Detection and Localization|[link](https://arxiv.org/pdf/2407.16554)||
|2025/5/7|Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network|[link](https://arxiv.org/pdf/2505.01880)||
|2025/4/11|Robust Audio Deepfake Detection using Ensemble Confidence Calibration, published in ICASSP2025|[link](https://ieeexplore.ieee.org/document/10889972)||
|2024/12/17|Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes|[link](https://arxiv.org/abs/2412.12619)||
|2022/5/10|NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality|[link](https://arxiv.org/abs/2205.04421)|[Samples](https://speechresearch.github.io/naturalspeech/)|
|2025/4/11|From Voices to Beats: Enhancing Music Deepfake Detection by Identifying Forgeries in Background, published in ICASSP2025|[link](https://ieeexplore.ieee.org/document/10890293)||
|2025/4/11|WaveSpect: A Hybrid Approach to Synthetic Audio Detection via Waveform and Spectrogram Analysis, published in ICASSP2025|[link](https://ieeexplore.ieee.org/document/10890188)||
|2025/4/11|Wave-Spectrogram Cross-Modal Aggregation for Audio Deepfake Detection, published in ICASSP2025|[link](https://ieeexplore.ieee.org/document/10890563?denied=)||
|2025/4/11|Fooling the Forgers: A Multi-Stage Framework for Audio Deepfake Detection, , published in ICASSP2025|[link](https://ieeexplore.ieee.org/document/10888175)||
|2022/2/28|Automatic speaker verification spoofing and deepfake detection using wav2vec 2.0 and data augmentation|[link](https://arxiv.org/abs/2202.12233)||
|2025/1/24|Generalizable Audio Deepfake Detection via Latent Space Refinement and Augmentation|[link](https://arxiv.org/abs/2501.14240)||
|2024/08/27, v4|Does Audio Deepfake Detection Generalize?|[link](https://arxiv.org/abs/2203.16263)||

### Surveys on Audio Deepfake Detection Models
* 2025/3 Audio Deepfake Detection: What Has Been Achieved and What Lies Ahead [link](https://pmc.ncbi.nlm.nih.gov/articles/PMC11991371/pdf/sensors-25-01989.pdf)
* 2025/8 A comprehensive survey with critical analysis for deepfake speech detection [link](https://www.sciencedirect.com/science/article/pii/S1574013725000334?casa_token=pX1nwj9YnMwAAAAA:0zt4Tpc2VDtldrhW1iKGivl6xPMatMqWZ27VfvmlgwliDIqe3F2GcirXECbE1-dR9fyUJKnr)
* 2024/12 From Audio Deepfake Detection to AI-Generated Music Detection – A Pathway and Overview [link](https://arxiv.org/pdf/2412.00571)
* 2024/10 Robust Deepfake Detection by Addressing Generalization and Trustworthiness Challenges: A Short Survey [link](https://dl.acm.org/doi/abs/10.1145/3689090.3689386)
* 2023/8 Audio Deepfake Detection: A Survey [link](https://arxiv.org/abs/2308.14970)

### A Survey on Audio-Language Models
* 2025/1 Audio-Language Models for Audio-Centric Tasks: A survey [link](https://arxiv.org/abs/2501.15177)

# Audio Deepfake Detection Implementation
## Datasets

### Rule-based replacement manipulation
* LAV-DF, Zhixi Cai, Kalin Stefanov, Abhinav Dhall, and Munawar Hayat. Do you really mean that? content driven audiovisual deepfake dataset and multimodal method for temporal forgery localization. In Proceedings of the International Conference on Digital Image Computing: Techniques and Applications, pages 1–10, 2022.
* (Partially Spoofed Dataset) HAD, Jiangyan Yi, Ye Bai, Jianhua Tao, Haoxin Ma, Zhengkun Tian, Chenglong Wang, Tao Wang, and Ruibo Fu. Halftruth: A partially fake audio detection dataset. In Proceedings of the Interspeech, pages 1654–1658, 2021.

### LLM-driven manipulation
* AV-Deepfake-1M, Zhixi Cai, Shreya Ghosh, Aman Pankaj Adatia, Munawar Hayat, Abhinav Dhall, Tom Gedeon, and kalin Stefanov. AV-Deepfake1M: A large-scale llm-driven audio-visual deepfake dataset. In Proceedings of the 32nd ACM International Conference on Multimedia, pages 7414–7423, 2024 [link](https://arxiv.org/pdf/2311.15308)
* Codecfake Dataset [link](https://github.com/xieyuankun/Codecfake)
* (Partially Fake Speech Dataset) LlamaPartialSpoof, H.-T. Luong, I. Rimon, H. Permuter, K. A. Lee, and E. S. Chng, "Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation," arXiv preprint arXiv:2507.03468, 2025. [link](https://arxiv.org/abs/2409.14743)

### Spoofing and Speaker Verification Challenge Datasets
* ASVspoof2019 [link](https://datashare.ed.ac.uk/handle/10283/3336)
* ASVspoof2021 LA [link](https://zenodo.org/records/4837263#.YnDIinYzZhE)
* ASVspoof2021 DF [link](https://zenodo.org/records/4835108#.YnDIb3YzZhE)
* ASVspoof2021 dataset labels [link](https://www.asvspoof.org/index2021.html)
* ASVspoof5 [link](https://doi.org/10.5281/zenodo.14498691)
* ADD series, J. Yi et al., “Add 2022: The first audio deepfake detection challenge,” in ICASSP, 2022. and H. Zhang et al., “Add 2023: Audio deepfake detection challenge,” in ICASSP, 2023.

### Environmental Sound Detection
* In-The-Wild, Nicolas M Muller, Pavel Czempin, Franziska Dieckmann, Adam Froghyar, and Konstantin Bottinger, “Does audio deepfake detection generalize?,” Interspeech, 2022. [link](https://deepfake-total.com/in_the_wild)
* sound8k, J. Salamon, C. Jacoby, and J. P. Bello, “A dataset and taxonomy for urban sound research,” in 22nd ACM International Conference on Multimedia (ACM-MM’14), Orlando, FL, USA, Nov. 2014, pp. 1041–1044.

### Audio Deepfake Detection
* SpoofCeleb, a dataset designed for Speech Deepfake Detection (SDD) and Spoofing-robust Automatic Speaker Verification (SASV) [paper](https://arxiv.org/pdf/2409.17285v2)
* CVoice,  X. Li, K. Li, Y. Zheng, C. Yan, X. Ji, and W. Xu, “Safeear: Content privacy-preserving audio deepfake detection,” arXiv:2409.09272, 2024.
* WaveFake,  J. Frank and L. Schönherr, “Wavefake: A data set to facilitate audio deepfake detection,” arXiv preprint arXiv:2111.02813, 2021.
* FakeOrReal, R. Reimao and V. Tzerpos, “For: A dataset for synthetic speech detection,” in 2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD). IEEE, 2019, pp. 1–10.
* FakeAVCelebV2, H. Khalid, S. Tariq, M. Kim, and S. S. Woo, “Fakeavceleb: A novel audio-video multimodal deepfake dataset,” arXiv:2108.05080, 2021.
* ADD series, J. Yi et al., “Add 2022: The first audio deepfake detection challenge,” in ICASSP, 2022. and H. Zhang et al., “Add 2023: Audio deepfake detection challenge,” in ICASSP, 2023.
* Purdue speech dataset, K. Bhagtani, A. K. S. Yadav, P. Bestagini, and E. J. Delp, “Are Recent Deepfake Speech Generators Detectable?” in ACM Workshop on Information Hiding and Multimedia Security, 2024.
* R. Reimao and V. Tzerpos, "FoR: A Dataset for Synthetic Speech Detection," in Proceedings of the 10th International Symposium on Digital Forensics and Security (ISDFS), Oct. 2019, pp. 1–10, doi: 10.1109/SPED.2019.8906599. [link](https://bil.eecs.yorku.ca/wp-content/uploads/2020/01/FoR-Dataset_RR_VT_final.pdf)

### Music
* WildSVDD, Y. Zang, Y. Zhang, M. Heydari, and Z. Duan, “Singfake: Singing voice deepfake detection,” in ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2024, pp. 12 156–12 160.

### Multilingual Deepfake Detection
* MLAAD, N. M. Müller, P. Kawa, W. H. Choong, E. Casanova, E. Gölge, T. Müller, P. Syga, P. Sperl, and K. Böttinger, “Mlaad: The multi-language audio anti-spoofing dataset,” arXiv:2401.09512, 2024

### Multimodal Deepfake Detection
* FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset [paper](https://arxiv.org/abs/2108.05080)

### Emotion Fake Audio Detection
* EmoFake: An Initial Dataset for Emotion Fake Audio Detection [paper](https://aclanthology.org/2024.ccl-1.99/)


## Models
|Model|Type|Input -> Output|Code|
|:---|:---|:---|:---|
|Wav2vec XLS-R - multilingual speech representation model|Encoder|raw speech audio -> a sequence of contextualized feature embeddings|[GitHub](https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/README.md)|
|WavLM|Encoder| features received by CNN encoder -> Output representations from all Transformer encoder layers|[GitHub](https://github.com/microsoft/unilm/tree/master/wavlm)|
|AASIST|E2E(RawNet2-based encoder and a graph neural networks module)| Encoder: Speech waveform -> 2D feature |[GitHub](https://github.com/clovaai/aasist)|

# Speech Synthesis 
* Methods: Text-to-Speech (TTS) and Voice conversion (VC)

## Text-to-speech (TTS) or Voice conversion (VC) Papers
### In-context speech generation: 
* Voicebox [Le et al., 2023] is a NAR flow matching model.
* GSLM-family [Lakhotia et al., 2021, Kharitonov et al., 2021, Nguyen et al., 2022] are textless language models built upon HuBERT units [Hsu et al., 3 2021]
* VALL-E [Wang et al., 2023] is a text conditioned LM trained on Encodec [Defossez et al., 2022].
* NaturalSpeech2 [Shen et al., 2023] adopts the latent diffusion framework. 
* HiFi-GAN [Kong et al., 2020] is a GAN model for efficient and high-fidelity speech synthesis. [link](https://papers.nips.cc/paper/2020/hash/c5d736809766d46260d816d8dbc9eb44-Abstract.html)
 
## Surveys
* 2021/7 A Survey on Neural Speech Synthesis [link](https://arxiv.org/abs/2106.15561)
* 2020/11 An Overview of Voice Conversion and its Challenges: From Statistical Modeling to Deep Learning [link](https://arxiv.org/abs/2008.03648)
* 2022/11 A Survey on Voice Assistant Security: Attacks and Countermeasures [link](https://dl.acm.org/doi/full/10.1145/3527153?casa_token=oeQfttwZGhkAAAAA%3AcWy2YQdtkNI8IMp4lU_4it3bsOSPX2dJ1tLicDkeUtF_toLi6BWlwVPlziRQp07fBJ0rSYqaqCc)

# Audio Signal Processing
* Librosa (Python Library) tutorial: https://github.com/prodramp/publiccode/blob/master/machine_learning/python_audio_tutorial/
* PyTorch (Audio library for PyTorch): https://github.com/prodramp/publiccode/blob/master/machine_learning/python_audio_tutorial/
* openSMILE (Open-source toolkit for feature extraction): https://github.com/audeering/opensmile